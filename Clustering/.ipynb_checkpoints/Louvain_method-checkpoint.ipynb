{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- original paper is [here](https://arxiv.org/pdf/0803.0476.pdf)\n",
    "\n",
    "- community detection based on modularity maxization\n",
    "- modularity measures how densely connected clusters are compared to what would be expected at random\n",
    "- modularity is also an objective function if we employ optimization-based approach to comunity detection.\n",
    "\n",
    "# Background\n",
    "\n",
    "- In most large networks such as those listed above (facebook etc) there are several natural organization levels –communities divide themselves into sub-communities– and it is thus desirable to obtain community detection methods that reveal this hierarchical structure\n",
    "\n",
    "# Algorithm\n",
    "## Two-phases repetition\n",
    "### 1st Phase: Assign communities to maximize modularity\n",
    "\n",
    "```{python}\n",
    "Init: \n",
    "N <- number of nodes\n",
    "assign distinct community id to each node\n",
    "\n",
    "While still improve?:\n",
    "    For each i in range(N)\n",
    "        For each k in Neigh(i):\n",
    "            gain_k <- caclulate modularity gain of removing i from c_i and placing it to c_k ***This part can be easily computed by using Eqs(2)\n",
    "            # At each iteration, what will change in the arguments for get_dq() is:\n",
    "            ## C : current clustering\n",
    "            ## i_nbors_C: indices of i's neighbour\n",
    "            ## NOTE: i_nbors won't change!!! because we don't modify any weights during the first phase.\n",
    "            gain_list.append(gain_k)\n",
    "        if max(gain_list) > 0:\n",
    "            max_gain_node_id <- argmax(gain_list)\n",
    "            update current clustering C by removing i from c_i and placing it into c_{max_gain_node_id}\n",
    "            # C has all the detailed information for each clustering with node ids.\n",
    "            # At the first iteration, when an empty clustering is formed by removing, what should I do? \n",
    "            # I think we just squeeze the list in C (or just delete the cell for that empty clustering?)\n",
    "```\n",
    "### 2nd Phase: Construct a new weights of the newly assigned nodes in the new communites in the 1st Phase\n",
    "\n",
    "The second phase of the algorithm consists in building a new network whose nodes are now the communities found during the first phase.\n",
    "\n",
    "To do so, the weights of the links between the new nodes are given by the sum of the weight of the links between nodes in the corresponding two communities. (Isn't this taken care by compute_cluster_affinity(A,C)?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
